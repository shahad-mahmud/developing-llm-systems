{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Configs:\n",
    "    GPT_MODEL = \"gpt-4o\"\n",
    "\n",
    "settings = Configs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=settings.GPT_MODEL, temperature=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To use Sparse Distributed Processing Attention (SDPA) with BERT in the Hugging Face Transformers library, you need to follow these steps:\n",
       "\n",
       "1. **Install the Transformers library**:\n",
       "   ```bash\n",
       "   pip install transformers\n",
       "   ```\n",
       "\n",
       "2. **Load a BERT model with SDPA**:\n",
       "   ```python\n",
       "   from transformers import BertModel, BertTokenizer\n",
       "\n",
       "   # Load the tokenizer\n",
       "   tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
       "\n",
       "   # Load the BERT model with SDPA\n",
       "   model = BertModel.from_pretrained('bert-base-uncased', attention_type='sdpa')\n",
       "   ```\n",
       "\n",
       "3. **Tokenize your input text**:\n",
       "   ```python\n",
       "   text = \"Your input text here\"\n",
       "   inputs = tokenizer(text, return_tensors='pt')\n",
       "   ```\n",
       "\n",
       "4. **Pass the inputs through the model**:\n",
       "   ```python\n",
       "   outputs = model(**inputs)\n",
       "   ```\n",
       "\n",
       "This will allow you to use BERT with SDPA in the Transformers library. Note that the actual availability of SDPA might depend on the specific version of the library and the model support. Always refer to the latest [Hugging Face Transformers documentation](https://huggingface.co/transformers/) for updates and detailed usage."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"How can I use SDPA with BERT in transformers?  Be short and precise.\"\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "display(Markdown(response.content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
